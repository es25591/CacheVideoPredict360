{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258e4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57421441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loaded successfully\n",
      "Frame count: 1800\n",
      "FPS: 30.0\n",
      "Frame size: 3840 x 1920\n"
     ]
    }
   ],
   "source": [
    "video_path = r'C:\\Users\\es25591\\Workspace\\360dataset\\content\\saliency\\coaster_saliency.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if cap.isOpened():\n",
    "    print(\"Video loaded successfully\")\n",
    "    print(f\"Frame count: {int(cap.get(cv2.CAP_PROP_FRAME_COUNT))}\")\n",
    "    print(f\"FPS: {cap.get(cv2.CAP_PROP_FPS)}\")\n",
    "    print(f\"Frame size: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))} x {int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\")\n",
    "else:\n",
    "    print(\"Error: Could not open video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b782ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "count = 0\n",
    "attention_frames = []\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "while True:\n",
    "    ret_f, f = cap.read()\n",
    "    if not ret_f:\n",
    "        break\n",
    "    gray = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    attention_frames.append(gray)\n",
    "    \n",
    "    # print(f\"Frame {count}: shape={gray.shape}, dtype={gray.dtype}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1110bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheService:\n",
    "    \"\"\"\n",
    "    LRU Cache with a fixed disk capacity (in bytes) instead of a fixed\n",
    "    number of items.\n",
    "\n",
    "    Items are evicted (least recently used first) until there is enough\n",
    "    free capacity to store the new item. Size is estimated using:\n",
    "      - numpy arrays: value.nbytes\n",
    "      - bytes / bytearray: len(value)\n",
    "      - str: len(value.encode('utf-8'))\n",
    "      - fallback: 1 (minimal placeholder)\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity_bytes=5_000_000):  # default ~5 MB\n",
    "        self.capacity_bytes = int(capacity_bytes)\n",
    "        self.cache = {}            # key -> (value, size_bytes)\n",
    "        self.access_order = []     # LRU ordering (oldest at index 0)\n",
    "        self.used_bytes = 0\n",
    "\n",
    "    def _estimate_size(self, value):\n",
    "        try:\n",
    "            import numpy as _np\n",
    "            if isinstance(value, _np.ndarray):\n",
    "                return int(value.nbytes)\n",
    "        except Exception:\n",
    "            pass\n",
    "        if isinstance(value, (bytes, bytearray)):\n",
    "            return len(value)\n",
    "        if isinstance(value, str):\n",
    "            return len(value.encode('utf-8'))\n",
    "        # Fallback minimal size\n",
    "        return 1\n",
    "\n",
    "    def available_bytes(self):\n",
    "        return self.capacity_bytes - self.used_bytes\n",
    "\n",
    "    def usage_ratio(self):\n",
    "        if self.capacity_bytes == 0:\n",
    "            return 0.0\n",
    "        return self.used_bytes / self.capacity_bytes\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            # Update access order for LRU\n",
    "            self.access_order.remove(key)\n",
    "            self.access_order.append(key)\n",
    "            return self.cache[key][0]\n",
    "        return None\n",
    "\n",
    "    def put(self, key, value):\n",
    "        size = self._estimate_size(value)\n",
    "        # If item larger than total capacity, skip storing\n",
    "        if size > self.capacity_bytes:\n",
    "            print(f\"[Cache] Skipping '{key}': item size {size} > capacity {self.capacity_bytes}\")\n",
    "            return False\n",
    "\n",
    "        # If key exists, remove old size first\n",
    "        if key in self.cache:\n",
    "            old_val, old_size = self.cache[key]\n",
    "            self.access_order.remove(key)\n",
    "            self.used_bytes -= old_size\n",
    "            del self.cache[key]\n",
    "\n",
    "        # Evict LRU until enough space\n",
    "        while self.used_bytes + size > self.capacity_bytes and self.access_order:\n",
    "            lru_key = self.access_order.pop(0)\n",
    "            lru_val, lru_size = self.cache[lru_key]\n",
    "            self.used_bytes -= lru_size\n",
    "            del self.cache[lru_key]\n",
    "            print(f\"[Cache] Evicted '{lru_key}' to free {lru_size} bytes\")\n",
    "\n",
    "        # Store new item\n",
    "        self.cache[key] = (value, size)\n",
    "        self.access_order.append(key)\n",
    "        self.used_bytes += size\n",
    "        return True\n",
    "\n",
    "    def clear(self):\n",
    "        self.cache.clear()\n",
    "        self.access_order.clear()\n",
    "        self.used_bytes = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cache)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"CacheService(items={len(self.cache)}, used={self.used_bytes}B, \"\n",
    "                f\"capacity={self.capacity_bytes}B, usage={self.usage_ratio():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e601e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cache Service Simulation ===\n",
      "\n",
      "1. Adding frames to cache:\n",
      "   Cached frame_0, Cache size: 1\n",
      "   Cached frame_5, Cache size: 2\n",
      "   Cached frame_10, Cache size: 3\n",
      "   Cached frame_15, Cache size: 4\n",
      "   Cached frame_20, Cache size: 5\n",
      "   Cached frame_25, Cache size: 6\n",
      "   Cached frame_30, Cache size: 7\n",
      "\n",
      "2. Current cache size: 7\n",
      "\n",
      "3. Accessing cached frames:\n",
      "   Retrieved frame_5: True, shape: (1920, 3840)\n",
      "   Retrieved frame_100 (not cached): False\n",
      "\n",
      "4. Adding more frames to trigger LRU eviction:\n",
      "   Cached frame_35, Cache size: 8\n",
      "   Cached frame_40, Cache size: 9\n",
      "   Cached frame_45, Cache size: 10\n",
      "   Cached frame_50, Cache size: 10\n",
      "\n",
      "5. Checking evicted frames:\n",
      "   frame_0 still in cache: False\n",
      "   frame_5 still in cache: True (recently accessed)\n",
      "\n",
      "6. Clearing cache:\n",
      "   Cache size after clear: 0\n"
     ]
    }
   ],
   "source": [
    "# Create cache service instance with 2 MB capacity\n",
    "cache = CacheService(capacity_bytes=2_000_000)\n",
    "\n",
    "print(\"=== Cache Service (Capacity-Based) Simulation ===\\n\")\n",
    "print(\"Initial:\", cache)\n",
    "\n",
    "# Helper to report status\n",
    "def report(label):\n",
    "    print(f\"{label}: items={len(cache)}, used={cache.used_bytes}B, avail={cache.available_bytes()}B, usage={cache.usage_ratio():.2%}\")\n",
    "\n",
    "# Add some frames to cache\n",
    "print(\"1. Adding frames to cache (attempting first 15 frames):\")\n",
    "for i in range(0, 15):\n",
    "    ok = cache.put(f\"frame_{i}\", attention_frames[i])\n",
    "    status = \"stored\" if ok else \"skipped\"\n",
    "    print(f\"   {status:7} frame_{i} (size={cache._estimate_size(attention_frames[i])}B)\")\n",
    "report(\"After initial load\")\n",
    "\n",
    "# Access some cached frames (testing LRU reorder)\n",
    "print(\"\\n2. Accessing some frames to update LRU order:\")\n",
    "for i in [2, 5, 3]:\n",
    "    fr = cache.get(f\"frame_{i}\")\n",
    "    print(f\"   Access frame_{i}: {'hit' if fr is not None else 'miss'}\")\n",
    "report(\"After accesses\")\n",
    "\n",
    "# Add more frames to trigger eviction\n",
    "print(\"\\n3. Adding more frames to trigger LRU evictions:\")\n",
    "for i in range(30, 40):\n",
    "    ok = cache.put(f\"frame_{i}\", attention_frames[i])\n",
    "    status = \"stored\" if ok else \"skipped\"\n",
    "    print(f\"   {status:7} frame_{i} (size={cache._estimate_size(attention_frames[i])}B)\")\n",
    "report(\"After evictions\")\n",
    "\n",
    "# Check presence of earlier frames\n",
    "print(\"\\n4. Checking if early frames remain:\")\n",
    "for i in [0, 2, 5, 10]:\n",
    "    fr = cache.get(f\"frame_{i}\")\n",
    "    print(f\"   frame_{i}: {'present' if fr is not None else 'evicted'}\")\n",
    "report(\"Post check\")\n",
    "\n",
    "# Clear cache\n",
    "print(\"\\n5. Clearing cache:\")\n",
    "cache.clear()\n",
    "report(\"After clear\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
